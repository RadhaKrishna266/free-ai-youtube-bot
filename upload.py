import os
import asyncio
from pydub import AudioSegment
import edge_tts
import subprocess

# ================= FILE PATHS =================
IMAGE_FILE = "Image1.png"
RESIZED_IMAGE = "Image1_resized.png"
SCRIPT_FILE = "script.txt"

TANPURA_FILE = "audio/tanpura.mp3"
FINAL_VIDEO = "final_video_episode_1.mp4"

# ================= RESIZE IMAGE =================
def resize_image(input_file, output_file, width=1280, height=720):
    subprocess.run([
        "ffmpeg", "-y", "-i", input_file,
        "-vf", f"scale={width}:{height}",
        output_file
    ], check=True)
    print("‚úÖ Image resized successfully")

# ================= GENERATE TTS =================
async def generate_tts(text, output_file):
    communicate = edge_tts.Communicate(text, "hi-IN-SwaraNeural")
    await communicate.save(output_file)
    print(f"üé§ TTS generated: {output_file}")

# ================= READ SCRIPT =================
def get_script_text(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read().strip()

# ================= MERGE AUDIO =================
def merge_audio(start_tanpura_file, main_tts_files, om_file, end_tanpura_file, output_file):
    # Load and trim start/end tanpura
    start_tanpura = AudioSegment.from_file(start_tanpura_file)[:2000]  # 2 sec
    end_tanpura = AudioSegment.from_file(end_tanpura_file)[:4000]      # 4 sec

    # Load main narration files
    final_audio = start_tanpura
    for file in main_tts_files:
        final_audio += AudioSegment.from_file(file)

    # Add om namo narayan
    final_audio += AudioSegment.from_file(om_file)

    # Add end tanpura
    final_audio += end_tanpura

    final_audio.export(output_file, format="mp3")
    print(f"‚úÖ Audio merged: {output_file}")
    return output_file

# ================= CREATE VIDEO =================
def create_video(image_file, audio_file, output_file):
    subprocess.run([
        "ffmpeg", "-y",
        "-loop", "1",
        "-i", image_file,
        "-i", audio_file,
        "-c:v", "libx264",
        "-tune", "stillimage",
        "-c:a", "aac",
        "-b:a", "192k",
        "-pix_fmt", "yuv420p",
        "-shortest",
        output_file
    ], check=True)
    print(f"‚úÖ Final video created: {output_file}")

# ================= MAIN =================
async def main():
    # 1Ô∏è‚É£ Resize image
    resize_image(IMAGE_FILE, RESIZED_IMAGE)

    # 2Ô∏è‚É£ Prepare narrations
    start_narration_text = (
        üå∏ ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Æ‡§ø‡§§‡•ç‡§∞‡•ã‡§Ç! üå∏

‡§Ö‡§ó‡§∞ ‡§Ü‡§™ ‡§™‡§π‡§≤‡•á ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§¶‡•á‡§ñ ‡§ö‡•Å‡§ï‡•á ‡§π‡•à‡§Ç ‡§§‡•ã ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ üôè  
‡§î‡§∞ ‡§Ö‡§ó‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á‡§ñ ‡§™‡§æ‡§è, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡§π‡§≤‡•á ‡§¶‡•á‡§ñ‡•á‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡§•‡§æ ‡§∏‡§Æ‡§ù ‡§Æ‡•á‡§Ç ‡§Ü‡§è‡•§  )

    main_script_text = get_script_text(SCRIPT_FILE)
    end_narration_text = (
        "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§ ‡§Ü‡§™‡§®‡•á ‡§∏‡§®‡§æ‡§§‡§® ‡§ú‡•ç‡§û‡§æ‡§® ‡§ß‡§æ‡§∞‡§æ ‡§¶‡•á‡§ñ‡§æ‡•§ "
        "‡§π‡§Æ ‡§™‡•ç‡§∞‡§§‡§ø‡§¶‡§ø‡§® ‡§µ‡§ø‡§∑‡•ç‡§£‡•Å ‡§™‡•Å‡§∞‡§æ‡§£ ‡§ï‡•á ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á‡•§"
    )
    om_narayan_text = "‡•ê ‡§®‡§Æ‡•ã ‡§®‡§æ‡§∞‡§æ‡§Ø‡§£"

    # 3Ô∏è‚É£ Generate TTS files
    os.makedirs("tts", exist_ok=True)
    await generate_tts(start_narration_text, "tts/start.mp3")
    await generate_tts(main_script_text, "tts/main.mp3")
    await generate_tts(end_narration_text, "tts/end.mp3")
    await generate_tts(om_narayan_text, "tts/om_narayan.mp3")

    # 4Ô∏è‚É£ Merge all audio
    final_audio_file = merge_audio(
        TANPURA_FILE,
        ["tts/start.mp3", "tts/main.mp3", "tts/end.mp3"],
        "tts/om_narayan.mp3",
        TANPURA_FILE,
        "final_audio.mp3"
    )

    # 5Ô∏è‚É£ Create final video
    create_video(RESIZED_IMAGE, final_audio_file, FINAL_VIDEO)

# ================= RUN =================
if __name__ == "__main__":
    asyncio.run(main())